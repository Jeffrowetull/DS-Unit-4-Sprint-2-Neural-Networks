{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_432_Backprop_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4q-QbA8XtAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGrt9EYlCqY",
        "colab_type": "text"
      },
      "source": [
        "# Backpropagation Practice\n",
        "\n",
        "Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 0  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 1 |\n",
        "| 0  | 1  | 0  | 1 |\n",
        "| 1  | 0  | 0  | 1 |\n",
        "| 1  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 0  | 0 |\n",
        "\n",
        "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0gRrGnLaiVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(([0,0,1],\n",
        "              [0,1,1],\n",
        "              [1,0,1],\n",
        "              [0,1,0],\n",
        "              [1,0,0],\n",
        "              [1,1,1],\n",
        "              [0,0,0]\n",
        "             ), dtype=float)\n",
        "y=np.array(([0],\n",
        "            [1],\n",
        "            [1],\n",
        "            [1],\n",
        "            [1],\n",
        "            [0],\n",
        "            [0],\n",
        "           ), dtype=float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoTiXU1lbiOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "ea680131-12da-41d5-8c65-3ece70667b54"
      },
      "source": [
        "print(X)\n",
        "y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEREYT-3wI1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self):\n",
        "    \n",
        "    self.input = 3\n",
        "    self.hiddenNodes = 4\n",
        "    self.outputNodes = 1\n",
        "    \n",
        "    self.weights1= np.random.randn(self.input,self.hiddenNodes)\n",
        "    self.weights2= np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "  \n",
        "  def sigmoid(self, s):\n",
        "    return 1/ (1+np.exp(-s))\n",
        "  \n",
        "  def sigmoidPrime(self, s):\n",
        "    return s * (1 - s)\n",
        "  \n",
        "  def feed_forward(self,X):\n",
        "    '''\n",
        "    Calculate the NN inference using feed forward.\n",
        "    '''\n",
        "    \n",
        "    self.hidden_sum = np.dot(X, self.weights1)\n",
        "    \n",
        "    self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "    \n",
        "    self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
        "    \n",
        "    self.activated_output = self.sigmoid(self.output_sum)\n",
        "    \n",
        "    return self.activated_output\n",
        "  \n",
        "  def back_prop(self, X, y , o):\n",
        "    '''\n",
        "    Backward propagate through the network\n",
        "    '''\n",
        "    \n",
        "    self.o_error = y - o\n",
        "    self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
        "    \n",
        "    self.z2_error = self.o_delta.dot(self.weights2.T)\n",
        "    self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
        "    \n",
        "    self.weights1 += X.T.dot(self.z2_delta)\n",
        "    self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
        "    \n",
        "  def train(self, X, y):\n",
        "    o = self.feed_forward(X)\n",
        "    self.back_prop(X, y, o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2Vob0_vac9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36f6dd2f-3db4-4c22-b7c6-56f39c8edc24"
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "\n",
        "for i in range(1000):\n",
        "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 50 ==0):\n",
        "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
        "        print('Input: \\n', X)\n",
        "        print('Actual Output: \\n', y)\n",
        "        print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
        "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
        "    nn.train(X,y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------EPOCH 1---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.59934437]\n",
            " [0.67439014]\n",
            " [0.62998246]\n",
            " [0.66590727]\n",
            " [0.62316386]\n",
            " [0.70055945]\n",
            " [0.58365796]]\n",
            "Loss: \n",
            " 0.24103028895771733\n",
            "+---------EPOCH 2---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.57943757]\n",
            " [0.64936552]\n",
            " [0.61040758]\n",
            " [0.64053923]\n",
            " [0.60342084]\n",
            " [0.67632923]\n",
            " [0.56400529]]\n",
            "Loss: \n",
            " 0.23892642296845398\n",
            "+---------EPOCH 3---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.56792955]\n",
            " [0.63486649]\n",
            " [0.60075184]\n",
            " [0.62692209]\n",
            " [0.59465508]\n",
            " [0.66373547]\n",
            " [0.55356163]]\n",
            "Loss: \n",
            " 0.23796177553219583\n",
            "+---------EPOCH 4---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.56112581]\n",
            " [0.6264954 ]\n",
            " [0.59666257]\n",
            " [0.62009327]\n",
            " [0.59202973]\n",
            " [0.65792144]\n",
            " [0.5482367 ]]\n",
            "Loss: \n",
            " 0.23732027023107763\n",
            "+---------EPOCH 5---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.55671032]\n",
            " [0.6213312 ]\n",
            " [0.59537738]\n",
            " [0.61677199]\n",
            " [0.59246714]\n",
            " [0.6556225 ]\n",
            " [0.54546806]]\n",
            "Loss: \n",
            " 0.23676555784992023\n",
            "+---------EPOCH 50---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.39698394]\n",
            " [0.59428414]\n",
            " [0.62183697]\n",
            " [0.67195845]\n",
            " [0.70244968]\n",
            " [0.71924225]\n",
            " [0.44070561]]\n",
            "Loss: \n",
            " 0.19612674259622617\n",
            "+---------EPOCH 100---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.18788858]\n",
            " [0.65206416]\n",
            " [0.67250941]\n",
            " [0.7585373 ]\n",
            " [0.81417537]\n",
            " [0.73523653]\n",
            " [0.27166689]]\n",
            "Loss: \n",
            " 0.13868889155214406\n",
            "+---------EPOCH 150---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.12011399]\n",
            " [0.65613254]\n",
            " [0.70224903]\n",
            " [0.78033724]\n",
            " [0.86305094]\n",
            " [0.70935597]\n",
            " [0.19635021]]\n",
            "Loss: \n",
            " 0.11858198930353761\n",
            "+---------EPOCH 200---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.09554339]\n",
            " [0.63532868]\n",
            " [0.72663626]\n",
            " [0.79845698]\n",
            " [0.88864841]\n",
            " [0.67010486]\n",
            " [0.15789941]]\n",
            "Loss: \n",
            " 0.10626185052102889\n",
            "+---------EPOCH 250---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.08627286]\n",
            " [0.61219498]\n",
            " [0.75388933]\n",
            " [0.82570649]\n",
            " [0.89174902]\n",
            " [0.61826398]\n",
            " [0.13345623]]\n",
            "Loss: \n",
            " 0.09436623105879315\n",
            "+---------EPOCH 300---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.08441999]\n",
            " [0.64795534]\n",
            " [0.77462918]\n",
            " [0.84765396]\n",
            " [0.85404822]\n",
            " [0.53918151]\n",
            " [0.11167386]]\n",
            "Loss: \n",
            " 0.07565045242774211\n",
            "+---------EPOCH 350---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.07877613]\n",
            " [0.75314239]\n",
            " [0.78782435]\n",
            " [0.86017458]\n",
            " [0.83463529]\n",
            " [0.41031681]\n",
            " [0.10066467]]\n",
            "Loss: \n",
            " 0.04822182334311413\n",
            "+---------EPOCH 400---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.06753417]\n",
            " [0.82079737]\n",
            " [0.82762251]\n",
            " [0.87489098]\n",
            " [0.86545532]\n",
            " [0.30174182]\n",
            " [0.09784623]]\n",
            "Loss: \n",
            " 0.02868071360568609\n",
            "+---------EPOCH 450---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.05631094]\n",
            " [0.86110531]\n",
            " [0.86236753]\n",
            " [0.89280482]\n",
            " [0.88992742]\n",
            " [0.23184723]\n",
            " [0.09431902]]\n",
            "Loss: \n",
            " 0.01823733579279157\n",
            "+---------EPOCH 500---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.04760583]\n",
            " [0.88622202]\n",
            " [0.88627224]\n",
            " [0.90743909]\n",
            " [0.90627421]\n",
            " [0.18789361]\n",
            " [0.08991558]]\n",
            "Loss: \n",
            " 0.012698087888995598\n",
            "+---------EPOCH 550---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.04111459]\n",
            " [0.90297296]\n",
            " [0.90271704]\n",
            " [0.91829086]\n",
            " [0.91762954]\n",
            " [0.1588409 ]\n",
            " [0.08538079]]\n",
            "Loss: \n",
            " 0.009507173692029951\n",
            "+---------EPOCH 600---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.03620315]\n",
            " [0.91484983]\n",
            " [0.91451407]\n",
            " [0.92641104]\n",
            " [0.92593198]\n",
            " [0.13848635]\n",
            " [0.08110491]]\n",
            "Loss: \n",
            " 0.007503849124857932\n",
            "+---------EPOCH 650---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.03239203]\n",
            " [0.92369747]\n",
            " [0.92334838]\n",
            " [0.93267212]\n",
            " [0.93227448]\n",
            " [0.12349114]\n",
            " [0.07721586]]\n",
            "Loss: \n",
            " 0.00615413275443028\n",
            "+---------EPOCH 700---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.02935995]\n",
            " [0.93055076]\n",
            " [0.93020976]\n",
            " [0.9376477 ]\n",
            " [0.93729414]\n",
            " [0.11198689]\n",
            " [0.0737254 ]]\n",
            "Loss: \n",
            " 0.005193173446662341\n",
            "+---------EPOCH 750---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.0268936 ]\n",
            " [0.93602599]\n",
            " [0.93569986]\n",
            " [0.94170635]\n",
            " [0.94138084]\n",
            " [0.10287002]\n",
            " [0.07060246]]\n",
            "Loss: \n",
            " 0.004478821656260191\n",
            "+---------EPOCH 800---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.02484881]\n",
            " [0.94051023]\n",
            " [0.94020055]\n",
            " [0.94508997]\n",
            " [0.94478463]\n",
            " [0.09545393]\n",
            " [0.06780411]]\n",
            "Loss: \n",
            " 0.003929309887177551\n",
            "+---------EPOCH 850---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.0231257 ]\n",
            " [0.94425791]\n",
            " [0.94396432]\n",
            " [0.94796232]\n",
            " [0.94767276]\n",
            " [0.0892915 ]\n",
            " [0.06528758]]\n",
            "Loss: \n",
            " 0.003494782489161008\n",
            "+---------EPOCH 900---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.02165324]\n",
            " [0.94744283]\n",
            " [0.94716429]\n",
            " [0.95043772]\n",
            " [0.95016123]\n",
            " [0.0840799 ]\n",
            " [0.06301438]]\n",
            "Loss: \n",
            " 0.003143327640261461\n",
            "+---------EPOCH 950---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.02037976]\n",
            " [0.95018772]\n",
            " [0.94992301]\n",
            " [0.95259833]\n",
            " [0.95233306]\n",
            " [0.079607  ]\n",
            " [0.06095129]]\n",
            "Loss: \n",
            " 0.002853670551872832\n",
            "+---------EPOCH 1000---------+\n",
            "Input: \n",
            " [[0. 0. 1.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 1. 1.]\n",
            " [0. 0. 0.]]\n",
            "Actual Output: \n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n",
            "Predicted Output: \n",
            " [[0.01926684]\n",
            " [0.95258167]\n",
            " [0.95232956]\n",
            " [0.95450465]\n",
            " [0.95424927]\n",
            " [0.07571989]\n",
            " [0.05907017]]\n",
            "Loss: \n",
            " 0.002611131889315319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b-r70o8p2Dm",
        "colab_type": "text"
      },
      "source": [
        "## Try building/training a more complex MLP on a bigger dataset.\n",
        "\n",
        "Use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the cannonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
        "\n",
        "If you need inspiration, the internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MOPtYdk1HgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!wget 'yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "!wget 'yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "!wget 'yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "!wget 'yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JnzxebjeLXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip /content/t10k-images-idx3-ubyte.gz\n",
        "!gunzip /content/t10k-labels-idx1-ubyte.gz\n",
        "!gunzip /content/train-images-idx3-ubyte.gz\n",
        "!gunzip /content/train-labels-idx1-ubyte.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM5jVQdKf0Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install python-mnist\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8EXbMrlhp1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mnist import MNIST\n",
        "\n",
        "mndata = MNIST('/content')\n",
        "\n",
        "images, labels = mndata.load_training()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc8mijLAiM4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "e300d864-38b8-4985-ec29-3942bcfd5d91"
      },
      "source": [
        "import random\n",
        "index = random.randrange(0, len(images))  # choose an index ;-)\n",
        "print(mndata.display(images[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "............................\n",
            "............................\n",
            "............................\n",
            "............................\n",
            "............................\n",
            ".....................@@.....\n",
            ".............@@@@@@.@@......\n",
            "........@@@@@@@@@@..........\n",
            "........@@@@@@..@@..........\n",
            "...........@@@..............\n",
            "............@...............\n",
            "............@...............\n",
            ".............@..............\n",
            ".............@@.............\n",
            "..............@@@...........\n",
            "................@@..........\n",
            ".................@@.........\n",
            ".................@@@........\n",
            ".................@@@........\n",
            "..............@@@@@.........\n",
            "............@@@@@@..........\n",
            "..........@@@@@.............\n",
            "........@@@@@...............\n",
            "......@@@@@@................\n",
            ".....@@@@...................\n",
            "............................\n",
            "............................\n",
            "............................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v--n3t8hs3Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(linewidth=200)\n",
        "X= []\n",
        "for m in range(0,1000):\n",
        "  X.append(np.reshape(images[m],(28,28)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeDayar9F_70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=labels[0:1000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB4-ZmEDn5lF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self):\n",
        "    \n",
        "    self.input = 28\n",
        "    self.hiddenNodes = 4\n",
        "    self.outputNodes = 1\n",
        "    #28x28 matrix array for first layer\n",
        "    self.weights1= np.random.randn(self.input,self.hiddenNodes)\n",
        "    #28x1 matrix from hidden to output\n",
        "    self.weights2= np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "  \n",
        "  def sigmoid(self, s):\n",
        "    return 1/ (1+np.exp(-s))\n",
        "  \n",
        "  def sigmoidPrime(self, s):\n",
        "    return s * (1 - s)\n",
        "  \n",
        "  def feed_forward(self,X):\n",
        "    '''\n",
        "    Calculate the NN inference using feed forward.\n",
        "    '''\n",
        "    \n",
        "    self.hidden_sum = np.dot(X, self.weights1)\n",
        "    \n",
        "    self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "    \n",
        "    self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
        "    \n",
        "    self.activated_output = self.sigmoid(self.output_sum)\n",
        "    \n",
        "    return self.activated_output\n",
        "  \n",
        "  def back_prop(self, X, y , o):\n",
        "    '''\n",
        "    Backward propagate through the network\n",
        "    '''\n",
        "    \n",
        "    self.o_error = y - o\n",
        "    self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
        "    \n",
        "    self.z2_error = self.o_delta.dot(self.weights2.T)\n",
        "    self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
        "    \n",
        "    self.weights1 += X.T.dot(self.z2_delta)\n",
        "    self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
        "    \n",
        "  def train(self, X, y):\n",
        "    o = self.feed_forward(X)\n",
        "    self.back_prop(X, y, o)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY9dtsTVsrwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "868e3ed7-b7a8-4b6c-b26b-34fe758c1ee5"
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "\n",
        "for i in range(1000):\n",
        "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 50 ==0):\n",
        "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
        "        #print('Input: \\n', X)\n",
        "        #print('Actual Output: \\n', y)\n",
        "        #print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
        "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
        "    nn.train(X,y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------EPOCH 1---------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in exp\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: \n",
            " 20.379609801903264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d6e6d1a5b0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print('Predicted Output: \\n', str(nn.feed_forward(X)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-db94a6b751ef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-db94a6b751ef>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(self, X, y, o)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_error\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2_error\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoidPrime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (1000,28,1000) and (1,4) not aligned: 1000 (dim 2) != 1 (dim 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwlRJSfBlCvy",
        "colab_type": "text"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Implement Cross Validation model evaluation on your MNIST implementation \n",
        "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
        " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
        "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
      ]
    }
  ]
}